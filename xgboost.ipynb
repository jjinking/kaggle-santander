{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sklearn\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda, munge, ml\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import santander\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import SGDClassifier as SGDClf\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following tutorial\n",
    "\n",
    "http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, feature_cols, df_train, df_test = santander.read_split(santander.FILE_TRAIN,\n",
    "                                                                                         santander.FILE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 58\n",
      "AUC Score (Train): 0.878746\n",
      "AUC Score (Test) : 0.834606\n"
     ]
    }
   ],
   "source": [
    "def cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50, missing=missing):\n",
    "    \n",
    "    # Train cv\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    dtrain = xgb.DMatrix(X_train.values, label=y_train.values, missing=missing)\n",
    "    cv_result = xgb.cv(\n",
    "        xgb_param, dtrain, num_boost_round=model.get_params()['n_estimators'], nfold=cv_nfold,\n",
    "        metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "    best_n_estimators = cv_result.shape[0]\n",
    "    model.set_params(n_estimators=best_n_estimators)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "    # Predict training data\n",
    "    y_hat_train = model.predict(X_train)\n",
    "\n",
    "    # Predict test data\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    \n",
    "    # Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"best n_estimators: {}\".format(best_n_estimators))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(y_train, y_hat_train))\n",
    "    print(\"AUC Score (Test) : %f\" % roc_auc_score(y_test,  y_hat_test))\n",
    "                    \n",
    "#     feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 112.355\n",
      "CPU times: user 6min 33s, sys: 6.79 s, total: 6min 40s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=58,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    " 'max_depth': [5],\n",
    " 'min_child_weight': [8, 9, 10],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | 9 | 0.83552176985969\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.reg_alpha, best_model.reg_lambda, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth | min_child_weight | test score | gridcv params\n",
    "----------|------------------|------------|--------------\n",
    "5 | 5 | 0.8357748141861523 | {'max_depth': [3, 5, 7, 9], 'min_child_weight': [1, 3, 5],}\n",
    "5 | 9 | 0.83552176985969 | {'max_depth': [4, 5, 6], 'min_child_weight': [8, 9, 10],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 187.796\n",
      "CPU times: user 10min 58s, sys: 11.3 s, total: 11min 9s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=58,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "  'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 | 0.8360898605728038\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.reg_alpha, best_model.reg_lambda, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma | test score | gridcv params\n",
    "----------|------------------|------------|--------------\n",
    "0.3 | 0.8360898605728038 | {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 58\n",
      "AUC Score (Train): 0.878746\n",
      "AUC Score (Test) : 0.834606\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "cv_fit_model(model1, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final parameters\n",
    "\n",
    "- n_estimators: 58\n",
    "- max_depth: 5\n",
    "- min_child_weight: 9\n",
    "- gamma: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 310.089\n",
      "CPU times: user 17min 51s, sys: 20.1 s, total: 18min 12s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=58,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'subsample': [0.65, 0.7, 0.75],\n",
    "    'colsample_bytree': [0.65, 0.7, 0.75],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 | 0.7 | 0.8364270758593435\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.reg_alpha, best_model.reg_lambda, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsample | colsample_bytree | test score | gridcv params\n",
    "----------|------------------|------------|--------------\n",
    "0.7 | 0.7 | 0.8364270758593435 | {'subsample': [0.6, 0.7, 0.8], 'colsample_bytree': [0.6, 0.7, 0.8],}\n",
    "0.7 | 0.7 | 0.8364270758593435 | {'subsample': [0.65, 0.7, 0.75], 'colsample_bytree': [0.65, 0.7, 0.75],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 847.463\n",
      "CPU times: user 48min 43s, sys: 54.6 s, total: 49min 37s\n",
      "Wall time: 14min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=58,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.3,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'reg_alpha': [0, 0.01, 0.02, 0.03, 0.05],\n",
    "    'reg_lambda': [0.98, 0.99, 1, 1.01, 1.02],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 | 0.99 | 0.8681091030364465 | 0.8362743989494978\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.reg_alpha, best_model.reg_lambda, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg_alpha | reg_lambda | train score | test score | gridcv params\n",
    "----------|---------|---------|------------|--------------\n",
    "0 | 1 | | 0.8364270758593435 | {'reg_alpha': [1e-2, 0.1, 0, 1, 10], 'reg_lambda': [1e-2, 0.1, 0, 1, 10],}\n",
    "0.01 | 0.99 | | 0.8362743989494978 | {'reg_alpha': [0, 0.01, 0.02, 0.03, 0.05], 'reg_lambda': [0.98, 0.99, 1, 1.01, 1.02],}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 58\n",
      "AUC Score (Train): 0.878746\n",
      "AUC Score (Test) : 0.834606\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "cv_fit_model(model1, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 58\n",
      "AUC Score (Train): 0.878746\n",
      "AUC Score (Test) : 0.834606\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate =0.005,\n",
    "    n_estimators=5000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0.3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "cv_fit_model(model1, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.cv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
