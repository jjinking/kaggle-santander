{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "D - go through all the columns, and figure out what the null values are represented as\n",
    "\n",
    "D - remove constant columns again, after setting all the null values in the columns\n",
    "\n",
    "D - impute NaN with entire train and test data: https://www.kaggle.com/cbrogan/titanic/xgboost-example-python\n",
    "\n",
    "D - find all categorical columns (that are not binary), and one-hot encode them\n",
    "\n",
    "D - Go through this tutorial: XGB Guidelines\n",
    "    http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "- check the columns in the original data with 9999999999 - may need to modify for some sort of ratio - not necessarily NaN\n",
    "\n",
    "- check columns that contain the word \"saldo\" - features that are linear combinations of other features\n",
    "    https://www.kaggle.com/sionek/santander-customer-satisfaction/reverse-feature-engineering/log\n",
    "\n",
    "- Check for weird columns, possibly useless\n",
    "\n",
    "- get list of features and their importances, and throw out useless ones\n",
    "    https://www.kaggle.com/mmueller/liberty-mutual-group-property-inspection-prediction/xgb-feature-importance-python/code\n",
    "    http://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "find advanced ways to deal with training data that has unbalanced labels - weighting?\n",
    "    - create more training data by slightly perturbing the sure data - synthetic features\n",
    "    - create L = # majority / # minority models, and ensemble them\n",
    "        - use different algorithms - i.e. svm and logistic regression with weights\n",
    "    - http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "transform data that has exponentially growing values, i.e. log\n",
    "\n",
    "try blending and stacking http://mlwave.com/kaggle-ensembling-guide/\n",
    "    - logistic regression\n",
    "    - tensorflow\n",
    "\n",
    "modify .9 predictions to 1.0, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sklearn\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda, munge\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import santander\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import SGDClassifier as SGDClf\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>train rows</th>\n",
       "      <th>train cols</th>\n",
       "      <th>test rows</th>\n",
       "      <th>test cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw</td>\n",
       "      <td>76020</td>\n",
       "      <td>371</td>\n",
       "      <td>75818</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dedup</td>\n",
       "      <td>71213</td>\n",
       "      <td>307</td>\n",
       "      <td>75818</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bin onehot</td>\n",
       "      <td>71213</td>\n",
       "      <td>363</td>\n",
       "      <td>75818</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>71213</td>\n",
       "      <td>357</td>\n",
       "      <td>75818</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>impute mean</td>\n",
       "      <td>71213</td>\n",
       "      <td>357</td>\n",
       "      <td>75818</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>impute median</td>\n",
       "      <td>71179</td>\n",
       "      <td>357</td>\n",
       "      <td>75818</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>impute freq</td>\n",
       "      <td>71179</td>\n",
       "      <td>357</td>\n",
       "      <td>75818</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>onehot int</td>\n",
       "      <td>71213</td>\n",
       "      <td>398</td>\n",
       "      <td>75818</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rm test const</td>\n",
       "      <td>71213</td>\n",
       "      <td>390</td>\n",
       "      <td>75818</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage  train rows  train cols  test rows  test cols\n",
       "0            raw       76020         371      75818        369\n",
       "1          dedup       71213         307      75818        306\n",
       "2     bin onehot       71213         363      75818        362\n",
       "3            NaN       71213         357      75818        356\n",
       "4    impute mean       71213         357      75818        356\n",
       "5  impute median       71179         357      75818        356\n",
       "6    impute freq       71179         357      75818        356\n",
       "7     onehot int       71213         398      75818        397\n",
       "8  rm test const       71213         390      75818        389"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO delete after comparing w new files - already implemented in santander.py\n",
    "def get_sizes(train_csv, test_csv):\n",
    "    df = pd.read_csv(train_csv)\n",
    "    df_test = pd.read_csv(test_csv, index_col='ID')\n",
    "    train_rows, train_cols = df.shape\n",
    "    test_rows, test_cols = df_test.shape\n",
    "    return train_rows, train_cols, test_rows, test_cols\n",
    "\n",
    "\n",
    "data_shapes = []\n",
    "for s, train_csv, test_csv in [\n",
    "    ('raw',           FILE_TRAIN,                                 FILE_TEST),\n",
    "    ('dedup',         FILE_TRAIN_DEDUP,                           FILE_TEST_DEDUP),\n",
    "    ('bin onehot',    FILE_TRAIN_DEDUP_ONEHOT,                    FILE_TEST_DEDUP_ONEHOT),\n",
    "    ('NaN',           FILE_TRAIN_DEDUP_ONEHOT_NA,                 FILE_TEST_DEDUP_ONEHOT_NA),\n",
    "    ('impute mean',   FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEAN,     FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEAN),\n",
    "    ('impute median', FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN,   FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN),\n",
    "    ('impute freq',   FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ,     FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_FREQ),\n",
    "    ('onehot int',    FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT,       FILE_TEST_DEDUP_ONEHOT_NA_ONEHOTINT),\n",
    "    ('rm test const', FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT_1TEST, FILE_TEST_DEDUP_ONEHOT_NA_ONEHOTINT_1TEST),]:\n",
    "    data_shapes.append((s,) + get_sizes(train_csv, test_csv))\n",
    "pd.DataFrame(data_shapes, columns=['stage', 'train rows', 'train cols', 'test rows', 'test cols'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix 'delta' cols that contain 9999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train, df_test, feature_cols = santander.read_data(FILE_TRAIN, FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_cols = []\n",
    "for c in df_train:\n",
    "    if 9999999999 in df[c].unique():\n",
    "        ratio_cols.append(c)\n",
    "        \n",
    "delta_cols = []\n",
    "for c in df_train:\n",
    "    if c.find('delta') == 0:\n",
    "        delta_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratio_cols), len(delta_cols), ratio_cols == delta_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delta_imp_amort_var18_1y3',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'delta_imp_aport_var13_1y3',\n",
       " 'delta_imp_aport_var17_1y3',\n",
       " 'delta_imp_aport_var33_1y3',\n",
       " 'delta_imp_compra_var44_1y3',\n",
       " 'delta_imp_reemb_var13_1y3',\n",
       " 'delta_imp_reemb_var17_1y3',\n",
       " 'delta_imp_reemb_var33_1y3',\n",
       " 'delta_imp_trasp_var17_in_1y3',\n",
       " 'delta_imp_trasp_var17_out_1y3',\n",
       " 'delta_imp_trasp_var33_in_1y3',\n",
       " 'delta_imp_trasp_var33_out_1y3',\n",
       " 'delta_imp_venta_var44_1y3',\n",
       " 'delta_num_aport_var13_1y3',\n",
       " 'delta_num_aport_var17_1y3',\n",
       " 'delta_num_aport_var33_1y3',\n",
       " 'delta_num_compra_var44_1y3',\n",
       " 'delta_num_reemb_var13_1y3',\n",
       " 'delta_num_reemb_var17_1y3',\n",
       " 'delta_num_reemb_var33_1y3',\n",
       " 'delta_num_trasp_var17_in_1y3',\n",
       " 'delta_num_trasp_var17_out_1y3',\n",
       " 'delta_num_trasp_var33_in_1y3',\n",
       " 'delta_num_trasp_var33_out_1y3',\n",
       " 'delta_num_venta_var44_1y3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000e+00    75923\n",
       " 1.000000e+10       70\n",
       "-1.000000e+00       18\n",
       " 1.000000e+00        3\n",
       " 4.000000e+00        2\n",
       "-3.333333e-01        1\n",
       "-6.666667e-01        1\n",
       " 2.500000e+00        1\n",
       " 5.000000e-01        1\n",
       "Name: delta_num_compra_var44_1y3, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 17\n",
    "c = ratio_cols[x]\n",
    "df[c].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000e+00    75716\n",
       " 1.000000e+10       78\n",
       "-1.000000e+00       14\n",
       " 1.000000e+00        3\n",
       "-8.333333e-01        1\n",
       "-6.666667e-01        1\n",
       " 2.000000e-01        1\n",
       "-8.666667e-01        1\n",
       " 5.000000e+00        1\n",
       "-5.000000e-01        1\n",
       "-7.500000e-01        1\n",
       "Name: delta_num_compra_var44_1y3, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[c].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75650.000000\n",
       "mean        -0.022113\n",
       "std          0.147300\n",
       "min         -1.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: delta_num_aport_var13_1y3, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[c] != 9999999999][c].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75441.000000\n",
       "mean        -0.021805\n",
       "std          0.147538\n",
       "min         -1.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          3.000000\n",
       "Name: delta_num_aport_var13_1y3, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test[c] != 9999999999][c].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 372), (75818, 370))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = munge.hash_features(df, columns=[c])\n",
    "df_test = munge.hash_features(df_test, columns=[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 373), (75818, 371))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "one-hot: 0, 1, 6, 9, 11, 12\n",
    "modify: 2, 3, 4, 5, 13, 14, 15, 16, 17\n",
    "7, 8, 10, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a - b) / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a b c\n",
    "0 0 0\n",
    "0 1 1\n",
    "1 0 \n",
    "1 1 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change 999999 to very negative numbers, i.e. -10\n",
    "change 999999 to very positive numbers, i.e. +10\n",
    "change 999999 to 1\n",
    "just add 3 columns increased, decreased, and stayed the same, and then change 999999 to null\n",
    "add 3 columns and remove orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates and constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP):\n",
    "    santander.read_process_write(santander.FILE_TRAIN,\n",
    "                                 santander.FILE_TEST,\n",
    "                                 santander.FILE_TRAIN_DEDUP,\n",
    "                                 santander.FILE_TEST_DEDUP,\n",
    "                                 santander.remove_duplicates_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode binary features - cols that start with 'ind_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP_ONEHOT):\n",
    "    santander.read_process_write(santander.FILE_TRAIN_DEDUP,\n",
    "                                 santander.FILE_TEST_DEDUP,\n",
    "                                 santander.FILE_TRAIN_DEDUP_ONEHOT,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT,\n",
    "                                 santander.one_hot_encode_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process known NaNs\n",
    "\n",
    "https://www.kaggle.com/c/santander-customer-satisfaction/forums/t/19291/data-dictionary/111360#post111360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def process_known_nans_bak():\n",
    "#     df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT)\n",
    "#     feature_cols = list(df.columns)\n",
    "#     feature_cols.remove(TARGET_COL)\n",
    "#     df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT, index_col='ID')\n",
    "    \n",
    "#     # Var3\n",
    "#     df['var3'] = df.var3.replace(-999999, np.nan)\n",
    "#     df_test['var3'] = df_test.var3.replace(-999999, np.nan)\n",
    "    \n",
    "#     # Find integer features with null values\n",
    "#     for c in feature_cols:\n",
    "#         if df[c].describe()['max'] == 9999999999:\n",
    "#             df[c] = df[c].replace(9999999999, np.nan)\n",
    "#             df_test[c] = df_test[c].replace(9999999999, np.nan)\n",
    "    \n",
    "#     # Remove constant columns\n",
    "#     df.drop(eda.find_const_cols(df), axis=1, inplace=True)\n",
    "\n",
    "#     # Remove duplicate columns and then rows again\n",
    "#     df = munge.remove_duplicates(df.T).T.drop_duplicates()\n",
    "    \n",
    "#     # Write to file\n",
    "#     df.to_csv(FILE_TRAIN_DEDUP_ONEHOT_NA, index=False)\n",
    "#     feature_cols = list(df.columns)\n",
    "#     feature_cols.remove(TARGET_COL)\n",
    "#     df_test[feature_cols].to_csv(FILE_TEST_DEDUP_ONEHOT_NA)\n",
    "    \n",
    "    \n",
    "# if not os.path.exists(FILE_TRAIN_DEDUP_ONEHOT_NA):\n",
    "#     process_known_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEAN):\n",
    "    santander.read_process_write(santander.FILE_TRAIN_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEAN,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEAN,\n",
    "                                 santander.impute_null_vals,\n",
    "                                 pass_features=True,\n",
    "                                 process_kwargs={'strategy': 'mean'})\n",
    "    \n",
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN):\n",
    "    santander.read_process_write(santander.FILE_TRAIN_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN,\n",
    "                                 santander.impute_null_vals,\n",
    "                                 pass_features=True,\n",
    "                                 process_kwargs={'strategy': 'median'})\n",
    "    \n",
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ):\n",
    "    santander.read_process_write(santander.FILE_TRAIN_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_FREQ,\n",
    "                                 santander.impute_null_vals,\n",
    "                                 pass_features=True,\n",
    "                                 process_kwargs={'strategy': 'most_frequent'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn some of the integer columns to categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(santander.FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT):\n",
    "    santander.read_process_write(santander.FILE_TRAIN_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA,\n",
    "                                 santander.FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT,\n",
    "                                 santander.FILE_TEST_DEDUP_ONEHOT_NA_ONEHOTINT,\n",
    "                                 santander.one_hot_int,\n",
    "                                 pass_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saldo_cols = []\n",
    "for c in df:\n",
    "    if c.find('saldo') > -1:\n",
    "        saldo_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_var13_0\n",
      "num_var13_largo_0\n",
      "num_var13_largo\n",
      "num_var13_medio_0\n",
      "num_var13\n",
      "saldo_var13_corto\n",
      "saldo_var13_largo\n",
      "saldo_var13_medio\n",
      "saldo_var13\n",
      "delta_imp_aport_var13_1y3\n",
      "delta_num_aport_var13_1y3\n",
      "imp_aport_var13_hace3\n",
      "imp_aport_var13_ult1\n",
      "imp_reemb_var13_ult1\n",
      "num_aport_var13_hace3\n",
      "num_aport_var13_ult1\n",
      "saldo_medio_var13_corto_hace2\n",
      "saldo_medio_var13_corto_hace3\n",
      "saldo_medio_var13_corto_ult1\n",
      "saldo_medio_var13_corto_ult3\n",
      "saldo_medio_var13_largo_hace2\n",
      "saldo_medio_var13_largo_hace3\n",
      "saldo_medio_var13_largo_ult1\n",
      "saldo_medio_var13_largo_ult3\n",
      "saldo_medio_var13_medio_hace2\n",
      "saldo_medio_var13_medio_ult3\n",
      "onehot_ind_var13_0_0\n",
      "onehot_ind_var13_0_1\n",
      "onehot_ind_var13_corto_0_0\n",
      "onehot_ind_var13_corto_0_1\n",
      "onehot_ind_var13_corto_0\n",
      "onehot_ind_var13_corto_1\n",
      "onehot_ind_var13_largo_0_0\n",
      "onehot_ind_var13_largo_0_1\n",
      "onehot_ind_var13_largo_0\n",
      "onehot_ind_var13_largo_1\n",
      "onehot_ind_var13_medio_0_0\n",
      "onehot_ind_var13_medio_0_1\n",
      "onehot_ind_var13_0\n",
      "onehot_ind_var13_1\n",
      "onehot_num_reemb_var13_ult1_0\n",
      "onehot_num_reemb_var13_ult1_3\n",
      "onehot_num_var13_corto_0_3\n",
      "onehot_num_var13_corto_0_6\n",
      "onehot_num_var13_corto_3\n",
      "onehot_num_var13_corto_6\n",
      "onehot_num_meses_var13_corto_ult3_0\n",
      "onehot_num_meses_var13_corto_ult3_1\n",
      "onehot_num_meses_var13_corto_ult3_2\n",
      "onehot_num_meses_var13_corto_ult3_3\n",
      "onehot_num_meses_var13_largo_ult3_0\n",
      "onehot_num_meses_var13_largo_ult3_1\n",
      "onehot_num_meses_var13_largo_ult3_2\n",
      "onehot_num_meses_var13_largo_ult3_3\n"
     ]
    }
   ],
   "source": [
    "for c in df:\n",
    "    if c.find('var13') > -1:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saldo_var1',\n",
       " 'saldo_var5',\n",
       " 'saldo_var6',\n",
       " 'saldo_var8',\n",
       " 'saldo_var12',\n",
       " 'saldo_var13_corto',\n",
       " 'saldo_var13_largo',\n",
       " 'saldo_var13_medio',\n",
       " 'saldo_var13',\n",
       " 'saldo_var14',\n",
       " 'saldo_var17',\n",
       " 'saldo_var18',\n",
       " 'saldo_var20',\n",
       " 'saldo_var24',\n",
       " 'saldo_var26',\n",
       " 'saldo_var25',\n",
       " 'saldo_var30',\n",
       " 'saldo_var31',\n",
       " 'saldo_var32',\n",
       " 'saldo_var33',\n",
       " 'saldo_var34',\n",
       " 'saldo_var37',\n",
       " 'saldo_var40',\n",
       " 'saldo_var42',\n",
       " 'saldo_var44',\n",
       " 'saldo_medio_var5_hace2',\n",
       " 'saldo_medio_var5_hace3',\n",
       " 'saldo_medio_var5_ult1',\n",
       " 'saldo_medio_var5_ult3',\n",
       " 'saldo_medio_var8_hace2',\n",
       " 'saldo_medio_var8_hace3',\n",
       " 'saldo_medio_var8_ult1',\n",
       " 'saldo_medio_var8_ult3',\n",
       " 'saldo_medio_var12_hace2',\n",
       " 'saldo_medio_var12_hace3',\n",
       " 'saldo_medio_var12_ult1',\n",
       " 'saldo_medio_var12_ult3',\n",
       " 'saldo_medio_var13_corto_hace2',\n",
       " 'saldo_medio_var13_corto_hace3',\n",
       " 'saldo_medio_var13_corto_ult1',\n",
       " 'saldo_medio_var13_corto_ult3',\n",
       " 'saldo_medio_var13_largo_hace2',\n",
       " 'saldo_medio_var13_largo_hace3',\n",
       " 'saldo_medio_var13_largo_ult1',\n",
       " 'saldo_medio_var13_largo_ult3',\n",
       " 'saldo_medio_var13_medio_hace2',\n",
       " 'saldo_medio_var13_medio_ult3',\n",
       " 'saldo_medio_var17_hace2',\n",
       " 'saldo_medio_var17_hace3',\n",
       " 'saldo_medio_var17_ult1',\n",
       " 'saldo_medio_var17_ult3',\n",
       " 'saldo_medio_var29_hace2',\n",
       " 'saldo_medio_var29_ult1',\n",
       " 'saldo_medio_var29_ult3',\n",
       " 'saldo_medio_var33_hace2',\n",
       " 'saldo_medio_var33_hace3',\n",
       " 'saldo_medio_var33_ult1',\n",
       " 'saldo_medio_var33_ult3',\n",
       " 'saldo_medio_var44_hace2',\n",
       " 'saldo_medio_var44_hace3',\n",
       " 'saldo_medio_var44_ult1',\n",
       " 'saldo_medio_var44_ult3']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saldo_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(df[['saldo_var13_corto', 'saldo_var13_largo', 'saldo_var13_medio']].sum(axis=1).values, df['saldo_var13'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>saldo_var13_corto</th>\n",
       "      <th>saldo_var13_largo</th>\n",
       "      <th>saldo_var13_medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   saldo_var13_corto  saldo_var13_largo  saldo_var13_medio\n",
       "0                0.0                0.0                0.0\n",
       "1              300.0                0.0                0.0\n",
       "2                0.0                0.0                0.0\n",
       "3                0.0                0.0                0.0\n",
       "4                0.0                0.0                0.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['saldo_var13_corto', 'saldo_var13_largo', 'saldo_var13_medio']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
