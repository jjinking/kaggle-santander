{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sklearn\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda, munge, ml\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TRAIN                               = 'data/train.csv'\n",
    "FILE_TRAIN_DEDUP                         = 'data/train.dedup.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT                  = 'data/train.dedup.onehot.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT_NA               = 'data/train.dedup.onehot.na.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEAN   = 'data/train.dedup.onehot.na.impute_mean.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN = 'data/train.dedup.onehot.na.impute_median.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ   = 'data/train.dedup.onehot.na.impute_freq.csv'\n",
    "FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT     = 'data/train.dedup.onehot.na.onehotint.csv'\n",
    "\n",
    "FILE_TEST                                = 'data/test.csv'\n",
    "FILE_TEST_DEDUP                          = 'data/test.dedup.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT                   = 'data/test.dedup.onehot.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT_NA                = 'data/test.dedup.onehot.na.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEAN    = 'data/test.dedup.onehot.na.impute_mean.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN  = 'data/test.dedup.onehot.na.impute_median.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_FREQ    = 'data/test.dedup.onehot.na.impute_freq.csv'\n",
    "FILE_TEST_DEDUP_ONEHOT_NA_ONEHOTINT      = 'data/test.dedup.onehot.na.onehotint.csv'\n",
    "\n",
    "FILE_SAMPLE_SUBMIT                       = 'data/sample_submission.csv'\n",
    "\n",
    "TARGET_COL                               = 'TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_csv(FILE_TRAIN, index_col='ID')\n",
    "df_test = pd.read_csv(FILE_TEST, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import SGDClassifier as SGDClf\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# # SGD with linear svm\n",
    "# sgdclf_svm = SGDClf(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
    "#                     n_iter=5, shuffle=True, n_jobs=1, random_state=0, learning_rate='optimal',\n",
    "#                     power_t=0.5, class_weight=None, warm_start=False, average=False)\n",
    "\n",
    "# # SGD with logistic regression\n",
    "# sgdclf_logistic = SGDClf(loss='log', penalty='l2', alpha=0.0001, l1_ratio=0.15,\n",
    "#                          n_iter=5, shuffle=True, n_jobs=1, random_state=0, learning_rate='optimal',\n",
    "#                          power_t=0.5, class_weight=None, warm_start=False, average=False)\n",
    "\n",
    "# descriptions_clfs = [\n",
    "#     (\"SGD linear svm\", sgdclf_svm),\n",
    "#     (\"SGD logistic\", sgdclf_logistic),\n",
    "#     (\"SVC Linear kernel\", SVC(C=1.0, kernel='linear', gamma='auto')),\n",
    "#     (\"SVC polynomial deg 2 kernel\", SVC(C=1.0, kernel='poly', degree=2, gamma='auto')),\n",
    "#     (\"SVC polynomial deg 3 kernel\", SVC(C=1.0, kernel='poly', degree=3, gamma='auto')),\n",
    "#     (\"SVC rbf kernel\", SVC(C=1.0, kernel='rbf', gamma='auto')),\n",
    "#     (\"KNeighbors, 3 neighbors\", KNC(n_neighbors=3, weights='uniform')),\n",
    "#     (\"RFC, 10 trees\", RFC(n_estimators=10, max_depth=None, min_samples_split=2, n_jobs=4)),\n",
    "#     (\"RFR, 60 trees\", RFR(n_estimators=60, max_depth=None, min_samples_split=2, n_jobs=8)),\n",
    "#     (\"LogisticRegression\", LogisticRegression(C=1.0, penalty='l2', random_state=0, multi_class='ovr', n_jobs=4)),\n",
    "#     (\"GradientBoostingClassifier\", GBC(loss='deviance', learning_rate=0.1, n_estimators=10, max_depth=None, min_samples_split=2)),\n",
    "#     (\"AdaBoostClassifier w SVC linear kernel\", ABC(SVC(C=1.0, kernel='linear', gamma='auto'), n_estimators=10, learning_rate=1.0, algorithm='SAMME'))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------+----------------+----------------+---------------+--------------------+-------------------+\n",
      "|   |        description         |  score_train   |   score_test   |   time_train  | time_predict_train | time_predict_test |\n",
      "+---+----------------------------+----------------+----------------+---------------+--------------------+-------------------+\n",
      "| 0 | GradientBoostingClassifier | 0.946571413377 | 0.535602898923 | 150.652132988 |   0.273437023163   |   0.110949993134  |\n",
      "+---+----------------------------+----------------+----------------+---------------+--------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "descriptions_clfs = [\n",
    "    (\"GradientBoostingClassifier\", GBC(loss='deviance', learning_rate=0.1, n_estimators=10, max_depth=None, min_samples_split=2)),\n",
    "]\n",
    "no_processing_prelim_results = ml.train_predict(\n",
    "    descriptions_clfs, X_train, y_train, X_test, y_test, scorer=roc_auc_score)\n",
    "\n",
    "eda.pprint(no_processing_prelim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    description     | score_train | score_test |   time_train  | time_predict_train | time_predict_test |\n",
    "|--------------------|-------------|------------|---------------|--------------------|-------------------|\n",
    "| LogisticRegression |     0.5     |  0.5       | 3.48322510719 |   0.116809129715   |  0.0402228832245  |\n",
    "| SGD linear svm     |     0.0     |  0.002183  | 0.378594      |   0.103345         |  0.047913         |\n",
    "| SGD logistic       |     0.0     |  0.002193  | 0.369095      |   0.108437         |  0.028139         |\n",
    "| RFC, 10  trees     |\t0.827815   |  0.083406  | 0.790865      |   0.24956          |  0.157566         |\n",
    "| RFC, 10  trees     | 0.859718579 | 0.51823037 | 0.60007190704 |   0.27322602272    |  0.155475139618   |\n",
    "| RFC, 50  trees     | 0.852189720 | 0.51933902 | 0.59852290153 |   0.24054980278    |  0.164301872253   |\n",
    "| RFC, 100 trees     | 0.855910125 | 0.51557289 | 0.58913993835 |   0.247822999954   |  0.163942098618   |\n",
    "| RFR, 10  trees     | 0.995971354 | 0.69631041 | 3.9711160659  |   0.294628143311   |  0.182307958603   |\n",
    "| RFR, 30  trees     | 0.996592169 | 0.74093666 | 9.39642286301 |   0.290091991425   |  0.176054954529   |\n",
    "| RFR, 40  trees     | 0.996521443 | 0.74854986 | 12.3622310162 |   0.289952039719   |  0.172476053238   |\n",
    "| RFR, 50  trees     | 0.996076029 | 0.70951576 | 4.8906700611  |   0.255952119827   |  0.165596961975   |\n",
    "| RFR, 60  trees     | 0.997072592 | 0.75873464 | 16.9496002197 |   0.258872032166   |  0.16659617424    |\n",
    "| RFR, 100 trees     | 0.996139285 | 0.70160749 | 4.0920510292  |   0.255863189697   |  0.167984962463   |\n",
    "| GradientBoostClf   | 0.946571413 | 0.53560289 | 150.652132988 |   0.273437023163   |  0.110949993134   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each iteration time(secs): 1104.896\n",
      "CPU times: user 7min 22s, sys: 1.62 s, total: 7min 23s\n",
      "Wall time: 18min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GridCV for Random Forest\n",
    "clf_rf = RFR(n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2,\n",
    "             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "             max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=2,\n",
    "             random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [670, 690],\n",
    "    'max_depth': [9],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(clf_rf,\n",
    "                                             X_train.values, y_train.values,\n",
    "                                             X_test.values, y_test.values,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=3,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89544301238220747, 0.8346291833431333, 670, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, best_model.predict(X_train)), best_score, best_model.n_estimators, best_model.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | train score | test score |\n",
    "-------------|-----------| ------------|------------|\n",
    "500          | 8         | 0.88057875  | 0.83468680 |\n",
    "600          | 9         | 0.89524552  | 0.83467362 |\n",
    "650          | 9         | 0.89546629  | 0.83467145 |\n",
    "670          | 9         | 0.89544301  | 0.83462918 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kg.save_submission(best_model.predict(df_test), 'submissions/unprocessed.rfr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dedup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 2523.339\n",
      "iteration 1\n",
      "Each iteration time(secs): 2475.204\n",
      "CPU times: user 13min 21s, sys: 2.18 s, total: 13min 23s\n",
      "Wall time: 1h 23min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GridCV for Random Forest\n",
    "clf_rf = RFR(n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2,\n",
    "             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "             max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=2,\n",
    "             random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'max_depth': [8, 9, 10, 11, 12],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(clf_rf,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=2,\n",
    "                                             n_cv=3,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 9, 0.89549650488440458, 0.83470427610605369)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.n_estimators, best_model.max_depth, roc_auc_score(y_train, best_model.predict(X_train)), best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | train score | test score | gridcv params\n",
    "-------------|-----------|-------------|------------|-------------------------\n",
    "700          | 9         | 0.895496504 | 0.83470427 | [100, 300, 500, 700] [8, 9, 10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kg.save_submission(best_model.predict(df_test), 'submissions/dedup.rfr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary One-hot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 565.568\n",
      "iteration 1\n",
      "Each iteration time(secs): 558.129\n",
      "CPU times: user 4min 27s, sys: 1.27 s, total: 4min 28s\n",
      "Wall time: 18min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GridCV for Random Forest\n",
    "clf_rf = RFR(n_estimators=10, criterion='mse', max_depth=None, min_samples_split=2,\n",
    "             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "             max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=2,\n",
    "             random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [198, 200, 202],\n",
    "    'max_depth': [7, 8, 9],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(clf_rf,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=2,\n",
    "                                             n_cv=3,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 9, 0.89489814266356504, 0.83431332657190871)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.n_estimators, best_model.max_depth, roc_auc_score(y_train, best_model.predict(X_train)), best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | train score | test score | gridcv params\n",
    "-------------|-----------|-------------|------------|-------------------------\n",
    "670          | 9         | 0.89544301  | 0.8346291  | \n",
    "600          | 10        | 0.90956541  | 0.8348116  | \n",
    "620          | 8         | 0.88074159  | 0.8347549  | \n",
    "640          | 8         | 0.88078282  | 0.8347805  | \n",
    "637          | 8         | 0.88076901  | 0.8347447  | \n",
    "630          | 8         | 0.88076376  | 0.8347627  | \n",
    "615          | 9         | 0.89537483  | 0.8346972  | \n",
    "200          | 10        | 0.90902188  | 0.8347227  | [100, 200, 400, 600, 800], [5, 10, 15]\n",
    "200          | 9         | 0.89489814  | 0.8343133  | [190, 200, 210], [9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kg.save_submission(best_model.predict(df_test), 'submissions/onehot.rfr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 1402.189\n",
      "iteration 1\n",
      "Each iteration time(secs): 1413.159\n",
      "CPU times: user 2h 52min 20s, sys: 2min 10s, total: 2h 54min 31s\n",
      "Wall time: 46min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# GridCV for Gradient Boost Model\n",
    "gbm = xgb.XGBRegressor(max_depth=3, n_estimators=300, learning_rate=0.05, nthread=4, objective='binary:logistic')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [125, 130, 135, 140],\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(gbm,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=2,\n",
    "                                             n_cv=3,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 5, 0.05, 0.87986838755861196, 0.84089022989516715)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.n_estimators, best_model.max_depth, best_model.learning_rate, roc_auc_score(y_train, best_model.predict(X_train)), best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | learning_rate | train score | test score | gridcv params\n",
    "-------------|-----------|---------------|-------------|------------|-------------------------\n",
    "100          | 5         | 0.05          | 0.868801790 | 0.83883443 | [5, 10, 20, 50, 100], [3, 5, 10, 20]\n",
    " 90          | 5         | 0.05          | 0.868166755 | 0.83869731 | [80, 88, 90, 92, 100, 150, 200], [4, 5, 6, 7], [0.01, 0.05, 0.1]\n",
    " 92          | 5         | 0.1           | 0.887339605 | 0.84173848 | [88, 90, 92], [5], [0.01, 0.05, 0.1]\n",
    "110          | 5         | 0.05          | 0.874559700 | 0.83983068 | [90, 100, 110], [4, 5, 6], [0.01, 0.05, 0.1]\n",
    "110          | 5         | 0.05          | 0.874559700 | 0.83983068 | [110, 150], [5], [0.01, 0.05, 0.1]\n",
    "130          | 5         | 0.05          | 0.879366381 | 0.84081928 | [110, 120, 130, 150], [5], [0.05]\n",
    "135          | 5         | 0.05          | 0.879868387 | 0.84089022 | [125, 130, 135, 140], [4, 5, 6], [0.01, 0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kg.save_submission(best_model.predict(df_test), 'submissions/onehot.xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binary one-hot data with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT_NA)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT_NA, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 172.080\n",
      "iteration 1\n",
      "Each iteration time(secs): 170.245\n",
      "iteration 2\n",
      "Each iteration time(secs): 165.891\n",
      "CPU times: user 31min 20s, sys: 21.1 s, total: 31min 41s\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# GridCV for Gradient Boost Model\n",
    "gbm = xgb.XGBRegressor(max_depth=3, n_estimators=300, learning_rate=0.05, nthread=4, objective='binary:logistic')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [141],\n",
    "    'max_depth': [4, 5],\n",
    "    'learning_rate': [0.05],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(gbm,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=3,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 | 5 | 0.05 | 0.880618056537 | 0.841465768053\n"
     ]
    }
   ],
   "source": [
    "print(\" | \".join(map(str, (best_model.n_estimators,\n",
    "                           best_model.max_depth,\n",
    "                           best_model.learning_rate,\n",
    "                           roc_auc_score(y_train, best_model.predict(X_train)),\n",
    "                           best_score))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | learning_rate | train score | test score | gridcv params\n",
    "-------------|-----------|---------------|-------------|------------|-------------------------\n",
    "100          | 6         | 0.05          | 0.888631658 | 0.84085649 | [100, 200, 300], [4, 5, 6], [0.01, 0.05, 0.1]\n",
    "120          | 6         | 0.05          | 0.894453891 | 0.84104419 | [80, 100, 120], [6, 8], [0.05]\n",
    "140          | 6         | 0.05          | 0.898613578 | 0.84165479 | [120, 130, 140], [6, 7], [0.05]\n",
    "142          | 6         | 0.05          | 0.898735910 | 0.84169320 | [140, 142, 144], [6], [0.05]\n",
    "141          | 5         | 0.05          | 0.880618056 | 0.84146576 | [141, 142], [4, 5, 6, 7], [0.03, 0.05, 0.07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kg.save_submission(best_model.predict(df_test), 'submissions/onehot.na.xgb.csv')  # 0.834738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=best_model.max_depth,\n",
    "                       n_estimators=best_model.n_estimators,\n",
    "                       learning_rate=best_model.learning_rate,\n",
    "                       nthread=4, objective='binary:logistic')\n",
    "kg.save_submission(gbm.fit(X_all, y_all).predict(df_test), 'submissions/onehot.na.xgb.csv')  # 0.837339 Best Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Imputed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEAN)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEAN, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880659902718 0.841968837657\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=5,\n",
    "                       n_estimators=141,\n",
    "                       learning_rate=0.05,\n",
    "                       nthread=4, objective='binary:logistic').fit(X_train, y_train)\n",
    "print(roc_auc_score(y_train, gbm.predict(X_train)), roc_auc_score(y_test, gbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 390.025\n",
      "iteration 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-4ecd0f93e63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nimport xgboost as xgb\\n\\n# GridCV for Gradient Boost Model\\ngbm = xgb.XGBRegressor(max_depth=3, n_estimators=300, learning_rate=0.05, nthread=4, objective='binary:logistic')\\n\\nparam_grid = {\\n    'n_estimators': [120, 130, 135],\\n    'max_depth': [3, 4],\\n}\\nbest_score, best_model = ml.fine_tune_params(gbm,\\n                                             X_train, y_train,\\n                                             X_test, y_test,\\n                                             param_grid,\\n                                             n_runs=3,\\n                                             n_cv=5,\\n                                             scorer=roc_auc_score,\\n                                             n_jobs=1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/hqmac028/datsci/datsci/ml.py\u001b[0m in \u001b[0;36mfine_tune_params\u001b[0;34m(clf, X_train, y_train, X_test, y_test, param_grid, n_runs, n_cv, scorer, n_jobs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         gs_clf = GSCV(clf, param_grid, cv=n_cv, n_jobs=n_jobs,\n\u001b[1;32m     73\u001b[0m                       scoring=make_scorer(scorer))\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0m_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    186\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# GridCV for Gradient Boost Model\n",
    "gbm = xgb.XGBRegressor(max_depth=3, n_estimators=300, learning_rate=0.05, nthread=4, objective='binary:logistic')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [120, 130, 135],\n",
    "    'max_depth': [3, 4],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(gbm,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=3,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\" | \".join(map(str, (best_model.n_estimators,\n",
    "                           best_model.max_depth,\n",
    "                           best_model.learning_rate,\n",
    "                           roc_auc_score(y_train, best_model.predict(X_train)),\n",
    "                           best_score))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators | max_depth | learning_rate | train score | test score | gridcv params\n",
    "-------------|-----------|---------------|-------------|------------|-------------------------\n",
    "130          | 4         |          0.05 | 0.864654067 | 0.84096933 | [130, 141, 140], [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=best_model.max_depth,\n",
    "                       n_estimators=best_model.n_estimators,\n",
    "                       learning_rate=best_model.learning_rate,\n",
    "                       nthread=4, objective='binary:logistic')\n",
    "kg.save_submission(gbm.fit(X_all, y_all).predict(df_test), 'submissions/impute_mean.xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880854942816 0.841071531047\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=5,\n",
    "                       n_estimators=141,\n",
    "                       learning_rate=0.05,\n",
    "                       nthread=4, objective='binary:logistic').fit(X_train, y_train)\n",
    "print(roc_auc_score(y_train, gbm.predict(X_train)), roc_auc_score(y_test, gbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT_NA_IMPUTE_FREQ, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880854942816 0.841071531047\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=5,\n",
    "                       n_estimators=141,\n",
    "                       learning_rate=0.05,\n",
    "                       nthread=4, objective='binary:logistic').fit(X_train, y_train)\n",
    "print(roc_auc_score(y_train, gbm.predict(X_train)), roc_auc_score(y_test, gbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train.dedup.onehot.na.impute_freq.csv'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train.dedup.onehot.na.impute_median.csv'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_TRAIN_DEDUP_ONEHOT_NA_IMPUTE_MEDIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       0       0\r\n"
     ]
    }
   ],
   "source": [
    "! diff data/train.dedup.onehot.na.impute_freq.csv data/train.dedup.onehot.na.impute_median.csv | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. One-hot int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "df = pd.read_csv(FILE_TRAIN_DEDUP_ONEHOT_NA_ONEHOTINT)\n",
    "df_test = pd.read_csv(FILE_TEST_DEDUP_ONEHOT_NA_ONEHOTINT, index_col='ID')\n",
    "\n",
    "# Split up the data\n",
    "feature_cols = list(df.columns)\n",
    "feature_cols.remove(TARGET_COL)\n",
    "X_all = df[feature_cols]  # feature values for all students\n",
    "y_all = df[TARGET_COL]\n",
    "\n",
    "test_size = 0.3 # 30 percent\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_size, random_state=0, stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# GridCV for Gradient Boost Model\n",
    "gbm = xgb.XGBRegressor(nthread=4, objective='binary:logistic')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "}\n",
    "best_score, best_model = ml.fine_tune_params(gbm,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=2,\n",
    "                                             n_cv=3,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\" | \".join(map(str, (best_model.n_estimators,\n",
    "                           best_model.max_depth,\n",
    "                           best_model.learning_rate,\n",
    "                           roc_auc_score(y_train, best_model.predict(X_train)),\n",
    "                           best_score))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators | max_depth | learning_rate | train score | test score | gridcv params\n",
    "-------------|-----------|---------------|-------------|------------|-------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=best_model.max_depth,\n",
    "                       n_estimators=best_model.n_estimators,\n",
    "                       learning_rate=best_model.learning_rate,\n",
    "                       nthread=4, objective='binary:logistic')\n",
    "kg.save_submission(gbm.fit(X_all, y_all).predict(df_test), 'submissions/onehotint.xgb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
