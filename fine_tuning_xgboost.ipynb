{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning XGBoost models\n",
    "\n",
    "Based on the tutorial at http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sklearn\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(rc={\n",
    "       \"figure.figsize\": (16, 10),\n",
    "       \"axes.titlesize\": 14})\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "from os.path import expanduser\n",
    "sys.path.insert(1, '{}/datsci'.format(expanduser('~')))\n",
    "from datsci import eda, munge, ml\n",
    "from datsci import kaggle as kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import santander\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.linear_model import SGDClassifier as SGDClf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, feature_cols, df_train, df_test = santander.read_split(\n",
    "    santander.FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT,\n",
    "    santander.FILE_TEST_DEDUP_VAR3_DELTA_1HOT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "/usr/local/lib/python3.5/site-packages/xgboost/training.py:272: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n",
      "Stopping. Best iteration: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 57\n",
      "AUC Score (Train): 0.877107\n",
      "AUC Score (Test) : 0.844208\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 5\n",
    "\n",
    "def cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50, missing=np.nan):\n",
    "    \n",
    "    # Train cv\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    dtrain = xgb.DMatrix(X_train.values, label=y_train.values, missing=missing)\n",
    "    cv_result = xgb.cv(\n",
    "        xgb_param, dtrain, num_boost_round=model.get_params()['n_estimators'], nfold=cv_nfold,\n",
    "        metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "    best_n_estimators = cv_result.shape[0]\n",
    "    model.set_params(n_estimators=best_n_estimators)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "    # Predict training data\n",
    "    y_hat_train = model.predict(X_train)\n",
    "\n",
    "    # Predict test data\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    \n",
    "    # Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"best n_estimators: {}\".format(best_n_estimators))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(y_train, y_hat_train))\n",
    "    print(\"AUC Score (Test) : %f\" % roc_auc_score(y_test,  y_hat_test))\n",
    "                    \n",
    "#     feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FILE_TRAIN\n",
    "\n",
    "Model Report\n",
    "best n_estimators: 58\n",
    "AUC Score (Train): 0.878746\n",
    "AUC Score (Test) : 0.834606\n",
    "\n",
    "\n",
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "Model Report\n",
    "best n_estimators: 57\n",
    "AUC Score (Train): 0.877107\n",
    "AUC Score (Test) : 0.844208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 321.738\n",
      "CPU times: user 18min 28s, sys: 20.6 s, total: 18min 49s\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=57,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    " 'max_depth': [3, 4, 5],\n",
    " 'min_child_weight': [6, 7, 8, 9],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 | 9 | 0.8664432060811502 | 0.843041822112627\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.max_depth, best_model.min_child_weight, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE_TRAIN\n",
    "\n",
    "max_depth | min_child_weight | train score | test score | gridcv params\n",
    "----------|------------------|-------------|------------|--------------\n",
    "5 | 5 |  | 0.8357748141861523 | {'max_depth': [3, 5, 7, 9], 'min_child_weight': [1, 3, 5],}\n",
    "5 | 9 |  | 0.83552176985969 | {'max_depth': [4, 5, 6], 'min_child_weight': [8, 9, 10],}\n",
    "\n",
    "\n",
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "max_depth | min_child_weight | train score | test score | gridcv params\n",
    "----------|------------------|-------------|------------|--------------\n",
    "5 | 9 | 0.8664432060811502 | 0.843041822112627 | {'max_depth': [4, 5, 6], 'min_child_weight': [8, 9, 10],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 160.232\n",
      "CPU times: user 9min 22s, sys: 9.15 s, total: 9min 31s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=57,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "  'gamma': [0.0, 0.02, 0.04, 0.06, 0.08],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 | 0.8664432060811502 | 0.843041822112627\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.gamma, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE_TRAIN\n",
    "\n",
    "gamma | train score | test score | gridcv params\n",
    "------|-------------|------------|--------------\n",
    "0.3 |  | 0.8360898605728038 | {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],}\n",
    "\n",
    "\n",
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "gamma | train score | test score | gridcv params\n",
    "------|-------------|------------|--------------\n",
    "0.0 | 0.8664432060811502 | 0.843041822112627 | {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "/usr/local/lib/python3.5/site-packages/xgboost/training.py:272: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n",
      "Stopping. Best iteration: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 76\n",
      "AUC Score (Train): 0.870831\n",
      "AUC Score (Test) : 0.844556\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final parameters\n",
    "\n",
    "- n_estimators: 76\n",
    "- max_depth: 5\n",
    "- min_child_weight: 9\n",
    "- gamma: 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 333.234\n",
      "CPU times: user 19min 45s, sys: 17.6 s, total: 20min 3s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=76,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'subsample': [0.75, 0.8, 0.85],\n",
    "    'colsample_bytree': [0.65, 0.7, 0.75],\n",
    "}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 | 0.7 | 0.8720600990462103 | 0.8450419887931837\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.subsample, best_model.colsample_bytree, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE_TRAIN\n",
    "\n",
    "subsample | colsample_bytree | train score | test score | gridcv params\n",
    "----------|------------------|-------------|------------|---------------\n",
    "0.7 | 0.7 |  | 0.8364270758593435 | {'subsample': [0.6, 0.7, 0.8], 'colsample_bytree': [0.6, 0.7, 0.8],}\n",
    "0.7 | 0.7 |  | 0.8364270758593435 | {'subsample': [0.65, 0.7, 0.75], 'colsample_bytree': [0.65, 0.7, 0.75],}\n",
    "\n",
    "\n",
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "subsample | colsample_bytree | train score | test score | gridcv params\n",
    "----------|------------------|-------------|------------|---------------\n",
    "0.8 | 0.7 | 0.8720600990462103 | 0.8450419887931837 | {'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9],}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "Each iteration time(secs): 917.254\n",
      "CPU times: user 54min 28s, sys: 48.4 s, total: 55min 16s\n",
      "Wall time: 15min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=76,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "param_grid = {'reg_alpha': [1e-2, 0.1, 0, 1, 10], 'reg_lambda': [1e-2, 0.1, 0, 1, 10],}\n",
    "\n",
    "best_score, best_model = ml.fine_tune_params(model,\n",
    "                                             X_train, y_train,\n",
    "                                             X_test, y_test,\n",
    "                                             param_grid,\n",
    "                                             n_runs=1,\n",
    "                                             n_cv=5,\n",
    "                                             scorer=roc_auc_score,\n",
    "                                             n_jobs=1,\n",
    "                                             gscv_kwargs={'iid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 1 | 0.8720600990462103 | 0.8450419887931837\n"
     ]
    }
   ],
   "source": [
    "train_score = roc_auc_score(y_train, best_model.predict(X_train))\n",
    "fine_tune_results = best_model.reg_alpha, best_model.reg_lambda, train_score, best_score\n",
    "print(\" | \".join([\"{}\"] * len(fine_tune_results)).format(*fine_tune_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILE_TRAIN\n",
    "\n",
    "reg_alpha | reg_lambda | train score | test score | gridcv params\n",
    "----------|------------|-------------|------------|--------------\n",
    "0 | 1 | | 0.8364270758593435 | {'reg_alpha': [1e-2, 0.1, 0, 1, 10], 'reg_lambda': [1e-2, 0.1, 0, 1, 10],}\n",
    "0.01 | 0.99 | | 0.8362743989494978 | {'reg_alpha': [0, 0.01, 0.02, 0.03, 0.05], 'reg_lambda': [0.98, 0.99, 1, 1.01, 1.02],}\n",
    "\n",
    "\n",
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "reg_alpha | reg_lambda | train score | test score | gridcv params\n",
    "----------|------------|-------------|------------|--------------\n",
    "0 | 1 | 0.8720600990462103 | 0.8450419887931837 | {'reg_alpha': [1e-2, 0.1, 0, 1, 10], 'reg_lambda': [1e-2, 0.1, 0, 1, 10],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "/usr/local/lib/python3.5/site-packages/xgboost/training.py:272: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n",
      "Stopping. Best iteration: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 75\n",
      "AUC Score (Train): 0.871799\n",
      "AUC Score (Test) : 0.845032\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "Model Report\n",
    "best n_estimators: 75\n",
    "AUC Score (Train): 0.871799\n",
    "AUC Score (Test) : 0.845032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "/usr/local/lib/python3.5/site-packages/xgboost/training.py:272: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n",
      "Stopping. Best iteration: 733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 734\n",
      "AUC Score (Train): 0.871176\n",
      "AUC Score (Test) : 0.845529\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=5000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=9,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic',\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "cv_fit_model(model, X_train, y_train, X_test, y_test, cv_nfold=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "\n",
    "Model Report\n",
    "best n_estimators: 734\n",
    "AUC Score (Train): 0.871176\n",
    "AUC Score (Test) : 0.845529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT\n",
    "kg.save_submission(model.predict(df_test), 'submissions/xgb.fine_tuned.1hot.csv')  # Score 0.837155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT trained on all data\n",
    "kg.save_submission(\n",
    "    model.fit(\n",
    "        df_train[feature_cols],\n",
    "        df_train[santander.TARGET_COL]\n",
    "    ).predict(df_test),\n",
    "    'submissions/xgb.fine_tuned.1hot.fit_all.csv')  # Score 0.838335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "/usr/local/lib/python3.5/site-packages/xgboost/training.py:272: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  idset = [randidx[(i * kstep): min(len(randidx), (i + 1) * kstep)] for i in range(nfold)]\n",
      "Stopping. Best iteration: 756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "best n_estimators: 757\n",
      "AUC Score (Train): 0.869186\n",
      "AUC Score (Test) : 0.873916\n"
     ]
    }
   ],
   "source": [
    "# FILE_TRAIN_DEDUP_VAR3_DELTA_1HOT trained on all data w cv\n",
    "model.n_estimators = 2000\n",
    "cv_fit_model(model,\n",
    "             df_train[feature_cols],\n",
    "             df_train[santander.TARGET_COL],\n",
    "             X_test, y_test,\n",
    "             cv_nfold=5, early_stopping_rounds=50)\n",
    "\n",
    "kg.save_submission(model.predict(df_test), 'submissions/xgb.fine_tuned.1hot.fit_all_cv.csv')  # Score 0.838332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.cv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
